{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f51536a-519b-4826-a7a5-506a8820d077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File './iemocap_train.csv' found. Size: 441434383 bytes\n",
      "File './iemocap_test.csv' found. Size: 114816810 bytes\n",
      "Using device: cuda\n",
      "Single GPU or CPU detected\n",
      "Successfully loaded './iemocap_train.csv' with 5904 rows.\n",
      "Successfully loaded './iemocap_test.csv' with 1476 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 20:03:38,075] A new study created in memory with name: no-name-a36c9def-5c2b-4044-b564-f57c6098769b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Optuna Trial 0 at 2025-03-21 20:03:38.075815\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 4\n",
      "  dropout: 0.24547619140839227\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.0003345522177503116\n",
      "  focal_gamma: 3.3709896152295458\n",
      "  temperature: 2.3774866674463504\n",
      "  weight_decay: 0.048351324370537664\n",
      "  max_norm: 0.9970966580791061\n",
      "  scheduler_factor: 0.44295720436939146\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 20:17:36,094] Trial 0 finished with value: 0.49138750799092357 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.24547619140839227, 'batch_size': 32, 'learning_rate': 0.0003345522177503116, 'focal_gamma': 3.3709896152295458, 'temperature': 2.3774866674463504, 'weight_decay': 0.048351324370537664, 'max_norm': 0.9970966580791061, 'scheduler_factor': 0.44295720436939146, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 0 at 2025-03-21 20:17:36.091219\n",
      "Best UAR: 0.4914\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 1 at 2025-03-21 20:17:36.095991\n",
      "Hyperparameters:\n",
      "  hidden_size: 128\n",
      "  num_layers: 4\n",
      "  dropout: 0.4787639973055768\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0009315376652218845\n",
      "  focal_gamma: 3.4226422513903634\n",
      "  temperature: 2.430664820085964\n",
      "  weight_decay: 0.06948020347732659\n",
      "  max_norm: 0.22426911461659618\n",
      "  scheduler_factor: 0.26409583188907426\n",
      "  scheduler_patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 20:39:51,510] Trial 1 finished with value: 0.4774760453958747 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.4787639973055768, 'batch_size': 16, 'learning_rate': 0.0009315376652218845, 'focal_gamma': 3.4226422513903634, 'temperature': 2.430664820085964, 'weight_decay': 0.06948020347732659, 'max_norm': 0.22426911461659618, 'scheduler_factor': 0.26409583188907426, 'scheduler_patience': 3}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 1 at 2025-03-21 20:39:51.508062\n",
      "Best UAR: 0.4775\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 2 at 2025-03-21 20:39:51.510997\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 4\n",
      "  dropout: 0.375725210652224\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.0002448046589309564\n",
      "  focal_gamma: 2.022496988902375\n",
      "  temperature: 4.247985674528052\n",
      "  weight_decay: 0.01687644778705345\n",
      "  max_norm: 0.8011536459215087\n",
      "  scheduler_factor: 0.39777836666044564\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 20:53:38,347] Trial 2 finished with value: 0.4749726927857858 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.375725210652224, 'batch_size': 32, 'learning_rate': 0.0002448046589309564, 'focal_gamma': 2.022496988902375, 'temperature': 4.247985674528052, 'weight_decay': 0.01687644778705345, 'max_norm': 0.8011536459215087, 'scheduler_factor': 0.39777836666044564, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 2 at 2025-03-21 20:53:38.345647\n",
      "Best UAR: 0.4750\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 3 at 2025-03-21 20:53:38.348801\n",
      "Hyperparameters:\n",
      "  hidden_size: 32\n",
      "  num_layers: 4\n",
      "  dropout: 0.45220902386150985\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.00013236623119233654\n",
      "  focal_gamma: 3.961941360888361\n",
      "  temperature: 3.37480854836799\n",
      "  weight_decay: 0.012431697951384955\n",
      "  max_norm: 0.826007151042206\n",
      "  scheduler_factor: 0.4287032151861675\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 21:16:00,305] Trial 3 finished with value: 0.44225135515458097 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.45220902386150985, 'batch_size': 16, 'learning_rate': 0.00013236623119233654, 'focal_gamma': 3.961941360888361, 'temperature': 3.37480854836799, 'weight_decay': 0.012431697951384955, 'max_norm': 0.826007151042206, 'scheduler_factor': 0.4287032151861675, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 3 at 2025-03-21 21:16:00.301804\n",
      "Best UAR: 0.4423\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 4 at 2025-03-21 21:16:00.307217\n",
      "Hyperparameters:\n",
      "  hidden_size: 128\n",
      "  num_layers: 2\n",
      "  dropout: 0.3402929306439805\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.0003243116068436412\n",
      "  focal_gamma: 3.445163353226194\n",
      "  temperature: 2.739541138487989\n",
      "  weight_decay: 0.09612832336610189\n",
      "  max_norm: 0.36731413081018927\n",
      "  scheduler_factor: 0.32866546766803295\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 21:26:15,527] Trial 4 finished with value: 0.4627403290591146 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.3402929306439805, 'batch_size': 32, 'learning_rate': 0.0003243116068436412, 'focal_gamma': 3.445163353226194, 'temperature': 2.739541138487989, 'weight_decay': 0.09612832336610189, 'max_norm': 0.36731413081018927, 'scheduler_factor': 0.32866546766803295, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 4 at 2025-03-21 21:26:15.524063\n",
      "Best UAR: 0.4627\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 5 at 2025-03-21 21:26:15.529212\n",
      "Hyperparameters:\n",
      "  hidden_size: 64\n",
      "  num_layers: 1\n",
      "  dropout: 0.3646147520197214\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.00011317096644385461\n",
      "  focal_gamma: 3.1307534506441783\n",
      "  temperature: 1.3366684500075845\n",
      "  weight_decay: 0.002247088419872853\n",
      "  max_norm: 0.6808607044693926\n",
      "  scheduler_factor: 0.20942189634065503\n",
      "  scheduler_patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 21:33:56,970] Trial 5 finished with value: 0.44341191762918514 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.3646147520197214, 'batch_size': 32, 'learning_rate': 0.00011317096644385461, 'focal_gamma': 3.1307534506441783, 'temperature': 1.3366684500075845, 'weight_decay': 0.002247088419872853, 'max_norm': 0.6808607044693926, 'scheduler_factor': 0.20942189634065503, 'scheduler_patience': 3}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 5 at 2025-03-21 21:33:56.966840\n",
      "Best UAR: 0.4434\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 6 at 2025-03-21 21:33:56.971871\n",
      "Hyperparameters:\n",
      "  hidden_size: 32\n",
      "  num_layers: 3\n",
      "  dropout: 0.49603305826252664\n",
      "  batch_size: 8\n",
      "  learning_rate: 0.0003127253274349453\n",
      "  focal_gamma: 2.2860046116244472\n",
      "  temperature: 3.5488191031415433\n",
      "  weight_decay: 0.044170190293706786\n",
      "  max_norm: 0.4740975896315738\n",
      "  scheduler_factor: 0.25044685702162106\n",
      "  scheduler_patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 22:08:59,145] Trial 6 finished with value: 0.46424666628651456 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.49603305826252664, 'batch_size': 8, 'learning_rate': 0.0003127253274349453, 'focal_gamma': 2.2860046116244472, 'temperature': 3.5488191031415433, 'weight_decay': 0.044170190293706786, 'max_norm': 0.4740975896315738, 'scheduler_factor': 0.25044685702162106, 'scheduler_patience': 3}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 6 at 2025-03-21 22:08:59.142802\n",
      "Best UAR: 0.4642\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 7 at 2025-03-21 22:08:59.146544\n",
      "Hyperparameters:\n",
      "  hidden_size: 128\n",
      "  num_layers: 3\n",
      "  dropout: 0.30578772798735687\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0006687544860314513\n",
      "  focal_gamma: 2.039385716780223\n",
      "  temperature: 4.012782971761322\n",
      "  weight_decay: 0.0032304492351044383\n",
      "  max_norm: 0.5511974428047175\n",
      "  scheduler_factor: 0.40834266900130844\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 22:29:41,062] Trial 7 finished with value: 0.4869938529212723 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.30578772798735687, 'batch_size': 16, 'learning_rate': 0.0006687544860314513, 'focal_gamma': 2.039385716780223, 'temperature': 4.012782971761322, 'weight_decay': 0.0032304492351044383, 'max_norm': 0.5511974428047175, 'scheduler_factor': 0.40834266900130844, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 7 at 2025-03-21 22:29:41.058516\n",
      "Best UAR: 0.4870\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 8 at 2025-03-21 22:29:41.063836\n",
      "Hyperparameters:\n",
      "  hidden_size: 128\n",
      "  num_layers: 4\n",
      "  dropout: 0.22132315355304463\n",
      "  batch_size: 8\n",
      "  learning_rate: 0.00020472948198111448\n",
      "  focal_gamma: 2.2654200357777965\n",
      "  temperature: 4.225666988472438\n",
      "  weight_decay: 0.0022197290294027\n",
      "  max_norm: 0.31126352183778144\n",
      "  scheduler_factor: 0.21376466067869448\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 23:09:00,053] Trial 8 finished with value: 0.4744054635895243 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.22132315355304463, 'batch_size': 8, 'learning_rate': 0.00020472948198111448, 'focal_gamma': 2.2654200357777965, 'temperature': 4.225666988472438, 'weight_decay': 0.0022197290294027, 'max_norm': 0.31126352183778144, 'scheduler_factor': 0.21376466067869448, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 8 at 2025-03-21 23:09:00.051587\n",
      "Best UAR: 0.4744\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 9 at 2025-03-21 23:09:00.055280\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 4\n",
      "  dropout: 0.34269009965598524\n",
      "  batch_size: 8\n",
      "  learning_rate: 0.0008121707990374298\n",
      "  focal_gamma: 2.5093479240983667\n",
      "  temperature: 1.5304808575952964\n",
      "  weight_decay: 0.0495688665898695\n",
      "  max_norm: 0.9742944345667733\n",
      "  scheduler_factor: 0.3717515297572044\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 23:49:04,935] Trial 9 finished with value: 0.47504238799305215 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.34269009965598524, 'batch_size': 8, 'learning_rate': 0.0008121707990374298, 'focal_gamma': 2.5093479240983667, 'temperature': 1.5304808575952964, 'weight_decay': 0.0495688665898695, 'max_norm': 0.9742944345667733, 'scheduler_factor': 0.3717515297572044, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 9 at 2025-03-21 23:49:04.933305\n",
      "Best UAR: 0.4750\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 10 at 2025-03-21 23:49:04.936663\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 2\n",
      "  dropout: 0.20614098805655634\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.0004914341706105221\n",
      "  focal_gamma: 2.8132555360738056\n",
      "  temperature: 2.1031959835834635\n",
      "  weight_decay: 0.02724828855354018\n",
      "  max_norm: 0.9819934742608504\n",
      "  scheduler_factor: 0.48526484990882457\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 23:59:31,811] Trial 10 finished with value: 0.4694494262212479 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.20614098805655634, 'batch_size': 32, 'learning_rate': 0.0004914341706105221, 'focal_gamma': 2.8132555360738056, 'temperature': 2.1031959835834635, 'weight_decay': 0.02724828855354018, 'max_norm': 0.9819934742608504, 'scheduler_factor': 0.48526484990882457, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 10 at 2025-03-21 23:59:31.808375\n",
      "Best UAR: 0.4694\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 11 at 2025-03-21 23:59:31.813230\n",
      "Hyperparameters:\n",
      "  hidden_size: 64\n",
      "  num_layers: 3\n",
      "  dropout: 0.27680280343491614\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0005486382855235905\n",
      "  focal_gamma: 3.7210124728828644\n",
      "  temperature: 4.7384365441455705\n",
      "  weight_decay: 0.005026089776500692\n",
      "  max_norm: 0.6340182807865362\n",
      "  scheduler_factor: 0.48439974223326815\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 00:19:55,365] Trial 11 finished with value: 0.4759944928825384 and parameters: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.27680280343491614, 'batch_size': 16, 'learning_rate': 0.0005486382855235905, 'focal_gamma': 3.7210124728828644, 'temperature': 4.7384365441455705, 'weight_decay': 0.005026089776500692, 'max_norm': 0.6340182807865362, 'scheduler_factor': 0.48439974223326815, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 11 at 2025-03-22 00:19:55.361812\n",
      "Best UAR: 0.4760\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 12 at 2025-03-22 00:19:55.366820\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 3\n",
      "  dropout: 0.27255435121172716\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0005407923110179471\n",
      "  focal_gamma: 2.977016888199257\n",
      "  temperature: 3.5220052604068752\n",
      "  weight_decay: 0.005477475221834772\n",
      "  max_norm: 0.15043853218081354\n",
      "  scheduler_factor: 0.1162861804993936\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 00:40:31,000] Trial 12 finished with value: 0.4828401974156244 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.27255435121172716, 'batch_size': 16, 'learning_rate': 0.0005407923110179471, 'focal_gamma': 2.977016888199257, 'temperature': 3.5220052604068752, 'weight_decay': 0.005477475221834772, 'max_norm': 0.15043853218081354, 'scheduler_factor': 0.1162861804993936, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 12 at 2025-03-22 00:40:30.996229\n",
      "Best UAR: 0.4828\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 13 at 2025-03-22 00:40:31.001316\n",
      "Hyperparameters:\n",
      "  hidden_size: 128\n",
      "  num_layers: 3\n",
      "  dropout: 0.2716602836768494\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.0004123953387604756\n",
      "  focal_gamma: 2.7321061724680646\n",
      "  temperature: 2.003385731863291\n",
      "  weight_decay: 0.0010011859415945867\n",
      "  max_norm: 0.5079281377048286\n",
      "  scheduler_factor: 0.4260693477508177\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 00:51:40,488] Trial 13 finished with value: 0.47822094599846027 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.2716602836768494, 'batch_size': 32, 'learning_rate': 0.0004123953387604756, 'focal_gamma': 2.7321061724680646, 'temperature': 2.003385731863291, 'weight_decay': 0.0010011859415945867, 'max_norm': 0.5079281377048286, 'scheduler_factor': 0.4260693477508177, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 13 at 2025-03-22 00:51:40.484348\n",
      "Best UAR: 0.4782\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 14 at 2025-03-22 00:51:40.489888\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 2\n",
      "  dropout: 0.30731253626631583\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0007179537510595963\n",
      "  focal_gamma: 3.2326627204462617\n",
      "  temperature: 3.0226212555477825\n",
      "  weight_decay: 0.00586588407849695\n",
      "  max_norm: 0.8246449132356163\n",
      "  scheduler_factor: 0.35593922030362873\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 01:09:00,600] Trial 14 finished with value: 0.4659605990962727 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.30731253626631583, 'batch_size': 16, 'learning_rate': 0.0007179537510595963, 'focal_gamma': 3.2326627204462617, 'temperature': 3.0226212555477825, 'weight_decay': 0.00586588407849695, 'max_norm': 0.8246449132356163, 'scheduler_factor': 0.35593922030362873, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 14 at 2025-03-22 01:09:00.597395\n",
      "Best UAR: 0.4660\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 15 at 2025-03-22 01:09:00.602124\n",
      "Hyperparameters:\n",
      "  hidden_size: 128\n",
      "  num_layers: 3\n",
      "  dropout: 0.4050664660444569\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.00016754755565385318\n",
      "  focal_gamma: 3.5374331050487564\n",
      "  temperature: 4.131237960970806\n",
      "  weight_decay: 0.0022448398180648123\n",
      "  max_norm: 0.668795883163082\n",
      "  scheduler_factor: 0.4410633753208489\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 01:20:07,583] Trial 15 finished with value: 0.4721142889667558 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.4050664660444569, 'batch_size': 32, 'learning_rate': 0.00016754755565385318, 'focal_gamma': 3.5374331050487564, 'temperature': 4.131237960970806, 'weight_decay': 0.0022448398180648123, 'max_norm': 0.668795883163082, 'scheduler_factor': 0.4410633753208489, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 15 at 2025-03-22 01:20:07.579140\n",
      "Best UAR: 0.4721\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 16 at 2025-03-22 01:20:07.585211\n",
      "Hyperparameters:\n",
      "  hidden_size: 64\n",
      "  num_layers: 1\n",
      "  dropout: 0.23907889291496934\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.00037879033188641873\n",
      "  focal_gamma: 2.5920802777035634\n",
      "  temperature: 4.7083771968883585\n",
      "  weight_decay: 0.021115534599223433\n",
      "  max_norm: 0.394416798301379\n",
      "  scheduler_factor: 0.31228865573765463\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 01:31:48,589] Trial 16 finished with value: 0.46893712056188336 and parameters: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.23907889291496934, 'batch_size': 16, 'learning_rate': 0.00037879033188641873, 'focal_gamma': 2.5920802777035634, 'temperature': 4.7083771968883585, 'weight_decay': 0.021115534599223433, 'max_norm': 0.394416798301379, 'scheduler_factor': 0.31228865573765463, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 16 at 2025-03-22 01:31:48.586247\n",
      "Best UAR: 0.4689\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 17 at 2025-03-22 01:31:48.591497\n",
      "Hyperparameters:\n",
      "  hidden_size: 32\n",
      "  num_layers: 4\n",
      "  dropout: 0.30900453223126817\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0002561374898649787\n",
      "  focal_gamma: 3.7811028673850307\n",
      "  temperature: 2.844590584705183\n",
      "  weight_decay: 0.008812335174059572\n",
      "  max_norm: 0.1013776924237777\n",
      "  scheduler_factor: 0.49963200087516385\n",
      "  scheduler_patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 01:54:00,063] Trial 17 finished with value: 0.4464098508334751 and parameters: {'hidden_size': 32, 'num_layers': 4, 'dropout': 0.30900453223126817, 'batch_size': 16, 'learning_rate': 0.0002561374898649787, 'focal_gamma': 3.7811028673850307, 'temperature': 2.844590584705183, 'weight_decay': 0.008812335174059572, 'max_norm': 0.1013776924237777, 'scheduler_factor': 0.49963200087516385, 'scheduler_patience': 3}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 17 at 2025-03-22 01:54:00.059052\n",
      "Best UAR: 0.4464\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 18 at 2025-03-22 01:54:00.065431\n",
      "Hyperparameters:\n",
      "  hidden_size: 128\n",
      "  num_layers: 3\n",
      "  dropout: 0.24684326094080755\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.0006677250679602036\n",
      "  focal_gamma: 3.001460757688573\n",
      "  temperature: 1.7940298547587412\n",
      "  weight_decay: 0.0035061595846070212\n",
      "  max_norm: 0.5765044937809454\n",
      "  scheduler_factor: 0.39115120512029167\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 02:05:08,436] Trial 18 finished with value: 0.4760020492824098 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.24684326094080755, 'batch_size': 32, 'learning_rate': 0.0006677250679602036, 'focal_gamma': 3.001460757688573, 'temperature': 1.7940298547587412, 'weight_decay': 0.0035061595846070212, 'max_norm': 0.5765044937809454, 'scheduler_factor': 0.39115120512029167, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 18 at 2025-03-22 02:05:08.432480\n",
      "Best UAR: 0.4760\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 19 at 2025-03-22 02:05:08.438207\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 2\n",
      "  dropout: 0.31139266663339793\n",
      "  batch_size: 8\n",
      "  learning_rate: 0.0004423482847767664\n",
      "  focal_gamma: 3.2367221394170915\n",
      "  temperature: 2.330777629614458\n",
      "  weight_decay: 0.0010539437035872242\n",
      "  max_norm: 0.8986679016516355\n",
      "  scheduler_factor: 0.44631086156481325\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 02:34:07,823] Trial 19 finished with value: 0.4801986893305679 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.31139266663339793, 'batch_size': 8, 'learning_rate': 0.0004423482847767664, 'focal_gamma': 3.2367221394170915, 'temperature': 2.330777629614458, 'weight_decay': 0.0010539437035872242, 'max_norm': 0.8986679016516355, 'scheduler_factor': 0.44631086156481325, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 19 at 2025-03-22 02:34:07.819828\n",
      "Best UAR: 0.4802\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 20 at 2025-03-22 02:34:07.825283\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 4\n",
      "  dropout: 0.40637879012030687\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.0009808508549512894\n",
      "  focal_gamma: 2.052043723714829\n",
      "  temperature: 3.7450825252155697\n",
      "  weight_decay: 0.00995563610921199\n",
      "  max_norm: 0.7577186405256255\n",
      "  scheduler_factor: 0.34034346672504356\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 02:47:59,933] Trial 20 finished with value: 0.4759070438980306 and parameters: {'hidden_size': 256, 'num_layers': 4, 'dropout': 0.40637879012030687, 'batch_size': 32, 'learning_rate': 0.0009808508549512894, 'focal_gamma': 2.052043723714829, 'temperature': 3.7450825252155697, 'weight_decay': 0.00995563610921199, 'max_norm': 0.7577186405256255, 'scheduler_factor': 0.34034346672504356, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 20 at 2025-03-22 02:47:59.928602\n",
      "Best UAR: 0.4759\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 21 at 2025-03-22 02:47:59.934727\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 3\n",
      "  dropout: 0.27330055067769066\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0006002819642433784\n",
      "  focal_gamma: 2.881047805815233\n",
      "  temperature: 3.148841629279862\n",
      "  weight_decay: 0.005245234520610715\n",
      "  max_norm: 0.10496272408325674\n",
      "  scheduler_factor: 0.10607618754871623\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 03:08:13,476] Trial 21 finished with value: 0.48332906249177604 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.27330055067769066, 'batch_size': 16, 'learning_rate': 0.0006002819642433784, 'focal_gamma': 2.881047805815233, 'temperature': 3.148841629279862, 'weight_decay': 0.005245234520610715, 'max_norm': 0.10496272408325674, 'scheduler_factor': 0.10607618754871623, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 21 at 2025-03-22 03:08:13.474222\n",
      "Best UAR: 0.4833\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 22 at 2025-03-22 03:08:13.478237\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 3\n",
      "  dropout: 0.24801562552687068\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0006892866205473743\n",
      "  focal_gamma: 2.390794167571051\n",
      "  temperature: 3.129782799229599\n",
      "  weight_decay: 0.0035059931746260794\n",
      "  max_norm: 0.22035998332095008\n",
      "  scheduler_factor: 0.16500783513749762\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 03:28:41,345] Trial 22 finished with value: 0.48589071780485443 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.24801562552687068, 'batch_size': 16, 'learning_rate': 0.0006892866205473743, 'focal_gamma': 2.390794167571051, 'temperature': 3.129782799229599, 'weight_decay': 0.0035059931746260794, 'max_norm': 0.22035998332095008, 'scheduler_factor': 0.16500783513749762, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 22 at 2025-03-22 03:28:41.341956\n",
      "Best UAR: 0.4859\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 23 at 2025-03-22 03:28:41.347645\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 3\n",
      "  dropout: 0.2464728588608683\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0007704907539584984\n",
      "  focal_gamma: 2.2449412969314633\n",
      "  temperature: 2.6275600095467277\n",
      "  weight_decay: 0.0035143839204688754\n",
      "  max_norm: 0.2686292560511328\n",
      "  scheduler_factor: 0.1673162371193696\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 03:48:58,376] Trial 23 finished with value: 0.4776135904456587 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.2464728588608683, 'batch_size': 16, 'learning_rate': 0.0007704907539584984, 'focal_gamma': 2.2449412969314633, 'temperature': 2.6275600095467277, 'weight_decay': 0.0035143839204688754, 'max_norm': 0.2686292560511328, 'scheduler_factor': 0.1673162371193696, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 23 at 2025-03-22 03:48:58.373139\n",
      "Best UAR: 0.4776\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 24 at 2025-03-22 03:48:58.378568\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 2\n",
      "  dropout: 0.20741289997174117\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0005985136343458644\n",
      "  focal_gamma: 2.4668219789139196\n",
      "  temperature: 3.9195018788926324\n",
      "  weight_decay: 0.0017461561121002254\n",
      "  max_norm: 0.41364578004341634\n",
      "  scheduler_factor: 0.2875057348722784\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 04:06:41,801] Trial 24 finished with value: 0.4724007939852342 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.20741289997174117, 'batch_size': 16, 'learning_rate': 0.0005985136343458644, 'focal_gamma': 2.4668219789139196, 'temperature': 3.9195018788926324, 'weight_decay': 0.0017461561121002254, 'max_norm': 0.41364578004341634, 'scheduler_factor': 0.2875057348722784, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 24 at 2025-03-22 04:06:41.797520\n",
      "Best UAR: 0.4724\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 25 at 2025-03-22 04:06:41.803433\n",
      "Hyperparameters:\n",
      "  hidden_size: 128\n",
      "  num_layers: 3\n",
      "  dropout: 0.2882732274372936\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.00032420082331257395\n",
      "  focal_gamma: 2.1432724920098196\n",
      "  temperature: 3.3213736647360927\n",
      "  weight_decay: 0.0031980118418412696\n",
      "  max_norm: 0.5598150609067346\n",
      "  scheduler_factor: 0.15143361118444715\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 04:26:38,323] Trial 25 finished with value: 0.47385775583119033 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.2882732274372936, 'batch_size': 16, 'learning_rate': 0.00032420082331257395, 'focal_gamma': 2.1432724920098196, 'temperature': 3.3213736647360927, 'weight_decay': 0.0031980118418412696, 'max_norm': 0.5598150609067346, 'scheduler_factor': 0.15143361118444715, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 25 at 2025-03-22 04:26:38.319885\n",
      "Best UAR: 0.4739\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 26 at 2025-03-22 04:26:38.324768\n",
      "Hyperparameters:\n",
      "  hidden_size: 64\n",
      "  num_layers: 4\n",
      "  dropout: 0.24112689266370835\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0008544544677984502\n",
      "  focal_gamma: 2.413307594840052\n",
      "  temperature: 4.444772600488784\n",
      "  weight_decay: 0.007181290614422502\n",
      "  max_norm: 0.19990918265254187\n",
      "  scheduler_factor: 0.463943693514107\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 04:49:01,026] Trial 26 finished with value: 0.48256620872844785 and parameters: {'hidden_size': 64, 'num_layers': 4, 'dropout': 0.24112689266370835, 'batch_size': 16, 'learning_rate': 0.0008544544677984502, 'focal_gamma': 2.413307594840052, 'temperature': 4.444772600488784, 'weight_decay': 0.007181290614422502, 'max_norm': 0.19990918265254187, 'scheduler_factor': 0.463943693514107, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 26 at 2025-03-22 04:49:01.024156\n",
      "Best UAR: 0.4826\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 27 at 2025-03-22 04:49:01.028317\n",
      "Hyperparameters:\n",
      "  hidden_size: 32\n",
      "  num_layers: 3\n",
      "  dropout: 0.32367306677147956\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.00044782996479392564\n",
      "  focal_gamma: 2.7121351943836784\n",
      "  temperature: 4.948566955466352\n",
      "  weight_decay: 0.0015128325437954672\n",
      "  max_norm: 0.7200643137492609\n",
      "  scheduler_factor: 0.3992496903137467\n",
      "  scheduler_patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 05:09:16,406] Trial 27 finished with value: 0.4612909719645962 and parameters: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.32367306677147956, 'batch_size': 16, 'learning_rate': 0.00044782996479392564, 'focal_gamma': 2.7121351943836784, 'temperature': 4.948566955466352, 'weight_decay': 0.0015128325437954672, 'max_norm': 0.7200643137492609, 'scheduler_factor': 0.3992496903137467, 'scheduler_patience': 4}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 27 at 2025-03-22 05:09:16.402899\n",
      "Best UAR: 0.4613\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 28 at 2025-03-22 05:09:16.408641\n",
      "Hyperparameters:\n",
      "  hidden_size: 256\n",
      "  num_layers: 2\n",
      "  dropout: 0.22902650040397707\n",
      "  batch_size: 8\n",
      "  learning_rate: 0.0006319257640538455\n",
      "  focal_gamma: 2.1771255166892662\n",
      "  temperature: 1.0234125630247206\n",
      "  weight_decay: 0.03018703975183937\n",
      "  max_norm: 0.9217844350515917\n",
      "  scheduler_factor: 0.1979982256696693\n",
      "  scheduler_patience: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 05:38:26,095] Trial 28 finished with value: 0.4837262981475506 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.22902650040397707, 'batch_size': 8, 'learning_rate': 0.0006319257640538455, 'focal_gamma': 2.1771255166892662, 'temperature': 1.0234125630247206, 'weight_decay': 0.03018703975183937, 'max_norm': 0.9217844350515917, 'scheduler_factor': 0.1979982256696693, 'scheduler_patience': 5}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 28 at 2025-03-22 05:38:26.091657\n",
      "Best UAR: 0.4837\n",
      "--------------------------------------------------\n",
      "\n",
      "Starting Optuna Trial 29 at 2025-03-22 05:38:26.096447\n",
      "Hyperparameters:\n",
      "  hidden_size: 128\n",
      "  num_layers: 4\n",
      "  dropout: 0.29190236852836393\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.0001810129708132406\n",
      "  focal_gamma: 3.391996625787396\n",
      "  temperature: 2.31183099941698\n",
      "  weight_decay: 0.013648061643674195\n",
      "  max_norm: 0.24619847089196523\n",
      "  scheduler_factor: 0.2942518307224353\n",
      "  scheduler_patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 05:51:31,010] Trial 29 finished with value: 0.4619558801840586 and parameters: {'hidden_size': 128, 'num_layers': 4, 'dropout': 0.29190236852836393, 'batch_size': 32, 'learning_rate': 0.0001810129708132406, 'focal_gamma': 3.391996625787396, 'temperature': 2.31183099941698, 'weight_decay': 0.013648061643674195, 'max_norm': 0.24619847089196523, 'scheduler_factor': 0.2942518307224353, 'scheduler_patience': 3}. Best is trial 0 with value: 0.49138750799092357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Optuna Trial 29 at 2025-03-22 05:51:31.004866\n",
      "Best UAR: 0.4620\n",
      "--------------------------------------------------\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'hidden_size': 256, 'num_layers': 4, 'dropout': 0.24547619140839227, 'batch_size': 32, 'learning_rate': 0.0003345522177503116, 'focal_gamma': 3.3709896152295458, 'temperature': 2.3774866674463504, 'weight_decay': 0.048351324370537664, 'max_norm': 0.9970966580791061, 'scheduler_factor': 0.44295720436939146, 'scheduler_patience': 5}\n",
      "Best UAR: 0.4914\n",
      "Best hyperparameters saved to: ./best_hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_EPOCHS = 40\n",
    "NUM_TRIALS = 30\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (recall_score, precision_score, f1_score,\n",
    "                             confusion_matrix, classification_report,\n",
    "                             roc_auc_score)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import optuna\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "SAVE_FOLDER = \"./\"\n",
    "if not os.path.exists(SAVE_FOLDER):\n",
    "    os.makedirs(SAVE_FOLDER)\n",
    "    print(f\"Created folder: {SAVE_FOLDER}\")\n",
    "\n",
    "TRAIN_CSV = \"./iemocap_train.csv\"\n",
    "TEST_CSV = \"./iemocap_test.csv\"\n",
    "CHECKPOINT_PATH = os.path.join(SAVE_FOLDER, \"lstm_best_model.pth\")\n",
    "HYPERPARAMS_PATH = os.path.join(SAVE_FOLDER, \"best_hyperparameters.json\")\n",
    "\n",
    "for csv_file in [TRAIN_CSV, TEST_CSV]:\n",
    "    if not os.path.exists(csv_file):\n",
    "        raise FileNotFoundError(f\"File '{csv_file}' not found in '{SAVE_FOLDER}'. Please upload it.\")\n",
    "    print(f\"File '{csv_file}' found. Size: {os.path.getsize(csv_file)} bytes\")\n",
    "\n",
    "SEED = 4321\n",
    "INPUT_SIZE = 29\n",
    "NUM_WORKERS = 14\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "else:\n",
    "    print(\"Single GPU or CPU detected\")\n",
    "\n",
    "# -----------------------------\n",
    "# Data Loading and Preprocessing\n",
    "# -----------------------------\n",
    "def load_csv_robust(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Successfully loaded '{file_path}' with {len(df)} rows.\")\n",
    "        return df\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError in '{file_path}': {e}\")\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='warn')\n",
    "        print(f\"Loaded '{file_path}' with skipped lines: {len(df)} rows.\")\n",
    "        return df\n",
    "\n",
    "df_train = load_csv_robust(TRAIN_CSV)\n",
    "df_test = load_csv_robust(TEST_CSV)\n",
    "\n",
    "def extract_features(row):\n",
    "    try:\n",
    "        features_list = ast.literal_eval(row[\"audio_features\"])\n",
    "        return np.array(features_list, dtype=np.float32)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing 'audio_features' in row: {row}. Error: {e}\")\n",
    "        return np.zeros((1, INPUT_SIZE), dtype=np.float32)\n",
    "\n",
    "df_train[\"Features\"] = df_train.apply(extract_features, axis=1)\n",
    "df_train[\"lengths\"] = df_train[\"Features\"].apply(lambda x: x.shape[0])\n",
    "df_test[\"Features\"] = df_test.apply(extract_features, axis=1)\n",
    "df_test[\"lengths\"] = df_test[\"Features\"].apply(lambda x: x.shape[0])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_train[\"Label\"] = le.fit_transform(df_train[\"emotion\"])\n",
    "df_test[\"Label\"] = le.transform(df_test[\"emotion\"])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(df_train[\"Label\"]), y=df_train[\"Label\"])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset and DataLoader\n",
    "# -----------------------------\n",
    "class IEMOCAPDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        features = torch.tensor(row[\"Features\"], dtype=torch.float32)\n",
    "        label = torch.tensor(row[\"Label\"], dtype=torch.long)\n",
    "        length = row[\"lengths\"]\n",
    "        return features, label, length\n",
    "\n",
    "def collate_fn(batch):\n",
    "    features, labels, lengths = zip(*batch)\n",
    "    features = [f if isinstance(f, torch.Tensor) else torch.tensor(f, dtype=torch.float32) for f in features]\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    features_padded = pad_sequence(features, batch_first=True, padding_value=0.0)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return features_padded, labels, lengths\n",
    "\n",
    "class_counts = df_train[\"Label\"].value_counts().sort_index()\n",
    "sample_weights = 1.0 / class_counts[df_train[\"Label\"]].values\n",
    "sample_weights = torch.tensor(sample_weights, dtype=torch.double)\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_dataset = IEMOCAPDataset(df_train)\n",
    "test_dataset = IEMOCAPDataset(df_test)\n",
    "\n",
    "# -----------------------------\n",
    "# Attention Mechanism\n",
    "# -----------------------------\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, temperature=1.0):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.score = nn.Linear(hidden_size, 1, bias=False)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, lstm_output, lengths):\n",
    "        attn_weights = torch.tanh(self.attn(lstm_output))\n",
    "        attn_scores = self.score(attn_weights).squeeze(-1)\n",
    "        mask = torch.arange(lstm_output.size(1), device=lstm_output.device).unsqueeze(0) >= lengths.to(lstm_output.device).unsqueeze(1)\n",
    "        attn_scores.masked_fill_(mask, float('-inf'))\n",
    "        attn_weights = torch.softmax(attn_scores / self.temperature, dim=1)\n",
    "        context = (attn_weights.unsqueeze(-1) * lstm_output).sum(dim=1)\n",
    "        return context, attn_weights\n",
    "\n",
    "# -----------------------------\n",
    "# Model Definition\n",
    "# -----------------------------\n",
    "class LSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout, temperature=1.0):\n",
    "        super(LSTMAttention, self).__init__()\n",
    "        self.lstm_emotion = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.attention = Attention(hidden_size, temperature=temperature)\n",
    "        self.fc_emotion = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm_emotion(packed)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        context, attn_weights = self.attention(out, lengths)\n",
    "        context = self.dropout(context)\n",
    "        emotion_out = self.fc_emotion(context)\n",
    "        return emotion_out, attn_weights\n",
    "\n",
    "# -----------------------------\n",
    "# Focal Loss\n",
    "# -----------------------------\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha if alpha is not None else 1.0\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss)\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation Metrics Function\n",
    "# -----------------------------\n",
    "def compute_metrics(labels, preds, outputs, num_classes):\n",
    "    metrics = {}\n",
    "    metrics['war'] = recall_score(labels, preds, average='micro')\n",
    "    metrics['uar'] = recall_score(labels, preds, average='macro')\n",
    "    metrics['precision_macro'] = precision_score(labels, preds, average='macro')\n",
    "    metrics['f1_macro'] = f1_score(labels, preds, average='macro')\n",
    "    metrics['precision_weighted'] = precision_score(labels, preds, average='weighted')\n",
    "    metrics['f1_weighted'] = f1_score(labels, preds, average='weighted')\n",
    "    metrics['conf_matrix'] = confusion_matrix(labels, preds)\n",
    "    if num_classes > 2:\n",
    "        try:\n",
    "            metrics['roc_auc_ovr'] = roc_auc_score(labels, outputs, multi_class='ovr')\n",
    "        except:\n",
    "            metrics['roc_auc_ovr'] = None\n",
    "    else:\n",
    "        metrics['roc_auc'] = roc_auc_score(labels, outputs[:, 1])\n",
    "    return metrics\n",
    "\n",
    "# -----------------------------\n",
    "# Objective Function for Optuna\n",
    "# -----------------------------\n",
    "def objective(trial):\n",
    "    print(f\"\\nStarting Optuna Trial {trial.number} at {pd.Timestamp.now()}\")\n",
    "\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [32, 64, 128, 256])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 4)\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-3, log=True)\n",
    "    focal_gamma = trial.suggest_float('focal_gamma', 2.0, 4.0)\n",
    "    temperature = trial.suggest_float('temperature', 1.0, 5.0)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-3, 1e-1, log=True)\n",
    "    max_norm = trial.suggest_float('max_norm', 0.1, 1.0)\n",
    "    scheduler_factor = trial.suggest_float('scheduler_factor', 0.1, 0.5)\n",
    "    scheduler_patience = trial.suggest_int('scheduler_patience', 3, 5)\n",
    "\n",
    "    params = {\n",
    "        'hidden_size': hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'dropout': dropout,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'focal_gamma': focal_gamma,\n",
    "        'temperature': temperature,\n",
    "        'weight_decay': weight_decay,\n",
    "        'max_norm': max_norm,\n",
    "        'scheduler_factor': scheduler_factor,\n",
    "        'scheduler_patience': scheduler_patience\n",
    "    }\n",
    "    print(\"Hyperparameters:\")\n",
    "    for param, value in params.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=sampler, num_workers=NUM_WORKERS,\n",
    "        collate_fn=collate_fn, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS,\n",
    "        collate_fn=collate_fn, pin_memory=True\n",
    "    )\n",
    "\n",
    "\n",
    "    model = LSTMAttention(INPUT_SIZE, hidden_size, num_layers, num_classes, dropout, temperature)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    model = torch.compile(model)\n",
    "\n",
    "    emotion_criterion = FocalLoss(alpha=class_weights.to(device), gamma=focal_gamma)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=scheduler_factor, patience=scheduler_patience)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_uar = 0.0\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for features, label, lengths in train_loader:\n",
    "            features = features.to(device)\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                emotion_out, _ = model(features, lengths)\n",
    "                loss = emotion_criterion(emotion_out, label)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            _, preds = torch.max(emotion_out, 1)\n",
    "            train_correct += (preds == label).sum().item()\n",
    "            train_total += label.size(0)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        all_labels, all_preds, all_outputs = [], [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for features, label, lengths in test_loader:\n",
    "                features = features.to(device)\n",
    "                label = label.to(device)\n",
    "                with autocast():\n",
    "                    emotion_out, _ = model(features, lengths)\n",
    "                    loss = emotion_criterion(emotion_out, label)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(emotion_out, 1)\n",
    "                all_labels.extend(label.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_outputs.extend(torch.softmax(emotion_out, dim=1).cpu().numpy())\n",
    "\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_outputs = np.array(all_outputs)\n",
    "        metrics = compute_metrics(all_labels, all_preds, all_outputs, num_classes)\n",
    "        uar = metrics['uar']\n",
    "        scheduler.step(uar)\n",
    "\n",
    "        if uar > best_uar:\n",
    "            best_uar = uar\n",
    "\n",
    "    print(f\"\\nFinished Optuna Trial {trial.number} at {pd.Timestamp.now()}\")\n",
    "    print(f\"Best UAR: {best_uar:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    return best_uar\n",
    "\n",
    "# -----------------------------\n",
    "# Run Optuna Optimization\n",
    "# -----------------------------\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=NUM_TRIALS)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(study.best_params)\n",
    "print(f\"Best UAR: {study.best_value:.4f}\")\n",
    "\n",
    "with open(HYPERPARAMS_PATH, 'w') as f:\n",
    "    json.dump({\n",
    "        'best_params': study.best_params,\n",
    "        'best_uar': study.best_value\n",
    "    }, f, indent=4)\n",
    "print(f\"Best hyperparameters saved to: {HYPERPARAMS_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
